{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/husseinlopez/diplomadoIA/blob/main/M1-6_Ejercicios_Validacion.ipynb)\n",
        "\n",
        "# M√≥dulo 1: Introducci√≥n a la Miner√≠a de Datos\n",
        "## Validaci√≥n y Evaluaci√≥n de Modelos\n",
        "\n",
        "**Diplomado en Inteligencia Artificial**  \n",
        "Dr. Irvin Hussein L√≥pez Nava\n",
        "CICESE - UABC\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivos de esta sesi√≥n\n",
        "\n",
        "1. **Comprender la importancia de la partici√≥n de datos** para evaluar generalizaci√≥n\n",
        "2. **Implementar diferentes esquemas de validaci√≥n**: Hold-out, k-Fold CV, Leave-One-Out\n",
        "3. **Aplicar m√©tricas de regresi√≥n**: MAE, MSE, RMSE, R¬≤\n",
        "4. **Aplicar m√©tricas de clasificaci√≥n**: Accuracy, Precision, Recall, F1, ROC-AUC, MCC\n",
        "5. **Evitar data leakage** en el pipeline de evaluaci√≥n\n",
        "6. **Interpretar resultados** considerando sesgo y varianza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Parte 1: Esquemas de Partici√≥n y Validaci√≥n\n",
        "\n",
        "**Objetivo**: Entender C√ìMO se dividen los datos, sin entrenar modelos todav√≠a.\n",
        "\n",
        "Veremos visualmente qu√© observaciones van a cada conjunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 ¬øPor qu√© particionar los datos?\n",
        "\n",
        "**Problema fundamental**:\n",
        "- El modelo se ajusta minimizando el error en los datos de entrenamiento\n",
        "- Si evaluamos en los mismos datos, el error ser√° **optimista**\n",
        "- No sabremos si el modelo **generaliza** a datos nuevos\n",
        "\n",
        "**Soluci√≥n**:\n",
        "- Separar datos en **entrenamiento** y **prueba**\n",
        "- Entrenar solo con training\n",
        "- Evaluar solo con test (datos \"no vistos\")\n",
        "\n",
        "En esta parte veremos la **mec√°nica de la partici√≥n**, no el modelado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Dataset de Ejemplo\n",
        "\n",
        "Usaremos un dataset peque√±o para visualizar claramente las particiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset peque√±o para visualizaci√≥n\n",
        "np.random.seed(42)\n",
        "\n",
        "# 30 observaciones para f√°cil visualizaci√≥n\n",
        "n_samples = 30\n",
        "X_visual = np.random.randn(n_samples, 5)\n",
        "y_visual = np.random.randint(0, 2, n_samples)\n",
        "\n",
        "# Crear DataFrame para mejor visualizaci√≥n\n",
        "df_visual = pd.DataFrame({\n",
        "    'ID': range(n_samples),\n",
        "    'Clase': y_visual,\n",
        "    'Feature_1': X_visual[:, 0],\n",
        "    'Feature_2': X_visual[:, 1]\n",
        "})\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DATASET DE EJEMPLO PARA VISUALIZACI√ìN\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTotal de observaciones: {n_samples}\")\n",
        "print(f\"\\nPrimeras 10 observaciones:\")\n",
        "print(df_visual.head(10))\n",
        "\n",
        "print(f\"\\nDistribuci√≥n de clases:\")\n",
        "print(df_visual['Clase'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Hold-Out Simple\n",
        "\n",
        "La estrategia m√°s b√°sica: una sola partici√≥n en train y test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hold-out 70-30\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_idx, test_idx = train_test_split(\n",
        "    np.arange(n_samples), \n",
        "    test_size=0.3, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"HOLD-OUT SIMPLE (70% Train - 30% Test)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nTotal: {n_samples} observaciones\")\n",
        "print(f\"Training: {len(train_idx)} observaciones ({100*len(train_idx)/n_samples:.0f}%)\")\n",
        "print(f\"Test: {len(test_idx)} observaciones ({100*len(test_idx)/n_samples:.0f}%)\")\n",
        "\n",
        "print(f\"\\n√çndices en Training: {sorted(train_idx.tolist())}\")\n",
        "print(f\"\\n√çndices en Test: {sorted(test_idx.tolist())}\")\n",
        "\n",
        "# Crear DataFrame para visualizaci√≥n\n",
        "df_partition = df_visual.copy()\n",
        "df_partition['Conjunto'] = 'Test'\n",
        "df_partition.loc[train_idx, 'Conjunto'] = 'Train'\n",
        "\n",
        "# Visualizaci√≥n\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Scatter plot mostrando la partici√≥n\n",
        "ax = axes[0]\n",
        "for conjunto, color, marker in [('Train', 'steelblue', 'o'), ('Test', 'orange', 's')]:\n",
        "    mask = df_partition['Conjunto'] == conjunto\n",
        "    ax.scatter(df_partition.loc[mask, 'Feature_1'], \n",
        "              df_partition.loc[mask, 'Feature_2'],\n",
        "              c=color, label=conjunto, s=100, alpha=0.7, \n",
        "              edgecolors='black', linewidth=1.5, marker=marker)\n",
        "\n",
        "ax.set_xlabel('Feature 1', fontsize=12)\n",
        "ax.set_ylabel('Feature 2', fontsize=12)\n",
        "ax.set_title('Visualizaci√≥n de la Partici√≥n Hold-Out', fontweight='bold', fontsize=14)\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "# Gr√°fico de barras por ID\n",
        "ax = axes[1]\n",
        "colors = ['steelblue' if c == 'Train' else 'orange' for c in df_partition['Conjunto']]\n",
        "ax.bar(df_partition['ID'], [1]*n_samples, color=colors, edgecolor='black', linewidth=0.5)\n",
        "ax.set_xlabel('ID de Observaci√≥n', fontsize=12)\n",
        "ax.set_ylabel('')\n",
        "ax.set_title('Observaciones por Conjunto\\n(Azul=Train, Naranja=Test)', fontweight='bold', fontsize=14)\n",
        "ax.set_yticks([])\n",
        "ax.grid(alpha=0.3, axis='x')\n",
        "\n",
        "# A√±adir l√≠nea separadora visual\n",
        "train_count = len(train_idx)\n",
        "ax.axvline(x=15, color='red', linestyle='--', linewidth=2, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úì Cada observaci√≥n est√° en exactamente UN conjunto\")\n",
        "print(f\"‚úì Train y Test son disjuntos (no se traslapan)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variabilidad del Hold-Out\n",
        "\n",
        "La partici√≥n depende del `random_state`. Veamos c√≥mo cambia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Probar diferentes semillas\n",
        "partitions = {}\n",
        "for seed in [42, 123, 999]:\n",
        "    train, test = train_test_split(\n",
        "        np.arange(n_samples), \n",
        "        test_size=0.3, \n",
        "        random_state=seed\n",
        "    )\n",
        "    partitions[f'Seed {seed}'] = {'train': sorted(train.tolist()), 'test': sorted(test.tolist())}\n",
        "\n",
        "# Visualizaci√≥n\n",
        "fig, axes = plt.subplots(3, 1, figsize=(16, 8))\n",
        "\n",
        "for idx, (name, partition) in enumerate(partitions.items()):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    colors = ['steelblue' if i in partition['train'] else 'orange' for i in range(n_samples)]\n",
        "    ax.bar(range(n_samples), [1]*n_samples, color=colors, edgecolor='black', linewidth=0.5)\n",
        "    ax.set_ylabel(name, fontsize=11, fontweight='bold')\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xlim(-0.5, n_samples-0.5)\n",
        "    ax.grid(alpha=0.3, axis='x')\n",
        "    \n",
        "    if idx == 2:\n",
        "        ax.set_xlabel('ID de Observaci√≥n', fontsize=12)\n",
        "    else:\n",
        "        ax.set_xticks([])\n",
        "\n",
        "plt.suptitle('Hold-Out con Diferentes Random States\\n(Azul=Train, Naranja=Test)', \n",
        "            fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"OBSERVACI√ìN IMPORTANTE\")\n",
        "print(\"=\"*80)\n",
        "print(\"‚Ä¢ Diferentes random_state ‚Üí diferentes particiones\")\n",
        "print(\"‚Ä¢ Esto introduce VARIABILIDAD en la evaluaci√≥n\")\n",
        "print(\"‚Ä¢ Soluci√≥n: k-Fold Cross-Validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 k-Fold Cross-Validation\n",
        "\n",
        "Divide los datos en k subconjuntos (folds) y rota cu√°l es test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# k-Fold con k=5\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"K-FOLD CROSS-VALIDATION (k=5)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTotal de observaciones: {n_samples}\")\n",
        "print(f\"N√∫mero de folds: 5\")\n",
        "print(f\"Tama√±o aproximado de cada fold: {n_samples//5}\")\n",
        "\n",
        "# Guardar informaci√≥n de cada fold\n",
        "folds_info = []\n",
        "\n",
        "for fold_idx, (train_indices, test_indices) in enumerate(kfold.split(X_visual), 1):\n",
        "    train_list = sorted(train_indices.tolist())\n",
        "    test_list = sorted(test_indices.tolist())\n",
        "    \n",
        "    folds_info.append({\n",
        "        'fold': fold_idx,\n",
        "        'train': train_list,\n",
        "        'test': test_list,\n",
        "        'train_size': len(train_list),\n",
        "        'test_size': len(test_list)\n",
        "    })\n",
        "    \n",
        "    print(f\"\\nFold {fold_idx}:\")\n",
        "    print(f\"  Train ({len(train_list)}): {train_list}\")\n",
        "    print(f\"  Test  ({len(test_list)}): {test_list}\")\n",
        "\n",
        "# Visualizaci√≥n de todos los folds\n",
        "fig, axes = plt.subplots(6, 1, figsize=(16, 10))\n",
        "\n",
        "# Primera fila: mostrar todas las observaciones\n",
        "ax = axes[0]\n",
        "ax.bar(range(n_samples), [1]*n_samples, color='gray', edgecolor='black', linewidth=0.5, alpha=0.3)\n",
        "ax.set_ylabel('Original', fontsize=10, fontweight='bold')\n",
        "ax.set_yticks([])\n",
        "ax.set_title('k-Fold Cross-Validation: Visualizaci√≥n de las 5 Particiones', \n",
        "            fontweight='bold', fontsize=14)\n",
        "ax.set_xticks([])\n",
        "\n",
        "# Siguientes filas: cada fold\n",
        "for idx, fold_info in enumerate(folds_info):\n",
        "    ax = axes[idx + 1]\n",
        "    \n",
        "    colors = ['steelblue' if i in fold_info['train'] else 'orange' for i in range(n_samples)]\n",
        "    ax.bar(range(n_samples), [1]*n_samples, color=colors, edgecolor='black', linewidth=0.5)\n",
        "    ax.set_ylabel(f\"Fold {fold_info['fold']}\", fontsize=10, fontweight='bold')\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xlim(-0.5, n_samples-0.5)\n",
        "    \n",
        "    if idx == 4:  # √öltimo fold\n",
        "        ax.set_xlabel('ID de Observaci√≥n', fontsize=12)\n",
        "    else:\n",
        "        ax.set_xticks([])\n",
        "\n",
        "# A√±adir leyenda\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='steelblue', edgecolor='black', label='Training'),\n",
        "    Patch(facecolor='orange', edgecolor='black', label='Test')\n",
        "]\n",
        "axes[0].legend(handles=legend_elements, loc='upper right', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úì Cada observaci√≥n es test EXACTAMENTE 1 vez\")\n",
        "print(f\"‚úì Cada observaci√≥n es training EXACTAMENTE {5-1} veces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verificaci√≥n: Cada observaci√≥n aparece como test una sola vez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contar cu√°ntas veces cada observaci√≥n es test\n",
        "test_count = np.zeros(n_samples, dtype=int)\n",
        "\n",
        "for fold_info in folds_info:\n",
        "    for idx in fold_info['test']:\n",
        "        test_count[idx] += 1\n",
        "\n",
        "# Verificaci√≥n\n",
        "print(\"=\"*80)\n",
        "print(\"VERIFICACI√ìN: Cobertura de k-Fold CV\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nCada observaci√≥n debe aparecer como test exactamente 1 vez:\")\n",
        "print(f\"  M√≠nimo: {test_count.min()}\")\n",
        "print(f\"  M√°ximo: {test_count.max()}\")\n",
        "print(f\"  Promedio: {test_count.mean():.1f}\")\n",
        "\n",
        "if np.all(test_count == 1):\n",
        "    print(f\"\\n‚úì VERIFICADO: Todas las observaciones son test exactamente 1 vez\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  ADVERTENCIA: Hay observaciones con conteo diferente de 1\")\n",
        "\n",
        "# Visualizaci√≥n de cobertura\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
        "bars = ax.bar(range(n_samples), test_count, edgecolor='black', linewidth=1)\n",
        "ax.axhline(y=1, color='red', linestyle='--', linewidth=2, label='Esperado: 1')\n",
        "ax.set_xlabel('ID de Observaci√≥n', fontsize=12)\n",
        "ax.set_ylabel('Veces que es Test', fontsize=12)\n",
        "ax.set_title('Cobertura de k-Fold CV\\n(Cada observaci√≥n debe ser test 1 vez)', \n",
        "            fontweight='bold', fontsize=14)\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3, axis='y')\n",
        "ax.set_ylim(0, 2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 Leave-One-Out Cross-Validation (LOOCV)\n",
        "\n",
        "Caso extremo: k = n (cada observaci√≥n es un fold)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "# LOOCV con dataset peque√±o (10 observaciones para visualizaci√≥n)\n",
        "n_small = 10\n",
        "X_loocv = X_visual[:n_small]\n",
        "y_loocv = y_visual[:n_small]\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"LEAVE-ONE-OUT CROSS-VALIDATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nObservaciones: {n_small}\")\n",
        "print(f\"N√∫mero de iteraciones: {loo.get_n_splits(X_loocv)} (una por observaci√≥n)\")\n",
        "\n",
        "# Mostrar primeras 5 iteraciones\n",
        "print(f\"\\nPrimeras 5 iteraciones:\")\n",
        "for fold_idx, (train_indices, test_indices) in enumerate(loo.split(X_loocv), 1):\n",
        "    if fold_idx > 5:\n",
        "        break\n",
        "    print(f\"  Iter {fold_idx}: Train={sorted(train_indices.tolist())}, Test={test_indices.tolist()}\")\n",
        "\n",
        "print(f\"  ...\")\n",
        "\n",
        "# Visualizaci√≥n de LOOCV\n",
        "fig, axes = plt.subplots(11, 1, figsize=(12, 12))\n",
        "\n",
        "# Primera fila: dataset original\n",
        "ax = axes[0]\n",
        "ax.bar(range(n_small), [1]*n_small, color='gray', edgecolor='black', alpha=0.3)\n",
        "ax.set_ylabel('Original', fontsize=9, fontweight='bold')\n",
        "ax.set_yticks([])\n",
        "ax.set_title('Leave-One-Out CV: 10 Iteraciones (k=n)', fontweight='bold', fontsize=13)\n",
        "ax.set_xticks([])\n",
        "\n",
        "# Siguientes filas: cada iteraci√≥n\n",
        "for iter_idx, (train_indices, test_indices) in enumerate(loo.split(X_loocv), 1):\n",
        "    ax = axes[iter_idx]\n",
        "    \n",
        "    colors = ['steelblue' if i in train_indices else 'orange' for i in range(n_small)]\n",
        "    ax.bar(range(n_small), [1]*n_small, color=colors, edgecolor='black', linewidth=0.8)\n",
        "    ax.set_ylabel(f'Iter {iter_idx}', fontsize=9, fontweight='bold')\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xlim(-0.5, n_small-0.5)\n",
        "    \n",
        "    if iter_idx == n_small:\n",
        "        ax.set_xlabel('ID de Observaci√≥n', fontsize=11)\n",
        "    else:\n",
        "        ax.set_xticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  LOOCV:\")\n",
        "print(f\"   ‚Ä¢ n iteraciones ‚Üí muy costoso computacionalmente\")\n",
        "print(f\"   ‚Ä¢ Cada fold entrena con n-1 observaciones\")\n",
        "print(f\"   ‚Ä¢ √ötil solo con datasets MUY peque√±os\")\n",
        "print(f\"   ‚Ä¢ En la pr√°ctica, k-Fold (k=5 o k=10) es preferible\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.6 Estratificaci√≥n en Clasificaci√≥n\n",
        "\n",
        "Preservar las proporciones de clase en cada fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Crear dataset peque√±o DESBALANCEADO\n",
        "np.random.seed(42)\n",
        "n_strat = 30\n",
        "y_desbal = np.array([0]*21 + [1]*9)  # 70% clase 0, 30% clase 1\n",
        "X_strat = np.random.randn(n_strat, 3)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ESTRATIFICACI√ìN EN CLASIFICACI√ìN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nDataset desbalanceado:\")\n",
        "unique, counts = np.unique(y_desbal, return_counts=True)\n",
        "for cls, count in zip(unique, counts):\n",
        "    print(f\"  Clase {cls}: {count} ({100*count/len(y_desbal):.1f}%)\")\n",
        "\n",
        "# k-Fold SIN estratificaci√≥n\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"K-FOLD SIN ESTRATIFICACI√ìN\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "kfold_no_strat = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "test_class_dist_no_strat = []\n",
        "for fold_idx, (train_idx, test_idx) in enumerate(kfold_no_strat.split(X_strat), 1):\n",
        "    y_test = y_desbal[test_idx]\n",
        "    class_1_count = (y_test == 1).sum()\n",
        "    class_1_pct = 100 * class_1_count / len(y_test)\n",
        "    test_class_dist_no_strat.append(class_1_pct)\n",
        "    print(f\"Fold {fold_idx}: {class_1_pct:5.1f}% clase 1 en test ({class_1_count}/{len(y_test)})\")\n",
        "\n",
        "# k-Fold CON estratificaci√≥n\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"K-FOLD CON ESTRATIFICACI√ìN\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "kfold_strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "test_class_dist_strat = []\n",
        "for fold_idx, (train_idx, test_idx) in enumerate(kfold_strat.split(X_strat, y_desbal), 1):\n",
        "    y_test = y_desbal[test_idx]\n",
        "    class_1_count = (y_test == 1).sum()\n",
        "    class_1_pct = 100 * class_1_count / len(y_test)\n",
        "    test_class_dist_strat.append(class_1_pct)\n",
        "    print(f\"Fold {fold_idx}: {class_1_pct:5.1f}% clase 1 en test ({class_1_count}/{len(y_test)})\")\n",
        "\n",
        "# Visualizaci√≥n comparativa\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Sin estratificaci√≥n\n",
        "ax = axes[0]\n",
        "folds = np.arange(1, 6)\n",
        "bars = ax.bar(folds, test_class_dist_no_strat, alpha=0.7, color='orange', edgecolor='black')\n",
        "ax.axhline(30, color='red', linestyle='--', linewidth=2, label='Proporci√≥n original: 30%')\n",
        "ax.set_xlabel('Fold', fontsize=12)\n",
        "ax.set_ylabel('% Clase 1 en Test', fontsize=12)\n",
        "ax.set_title('SIN Estratificaci√≥n\\n(Proporciones variables)', fontweight='bold', fontsize=14)\n",
        "ax.set_ylim(0, 50)\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "# A√±adir valores\n",
        "for bar, val in zip(bars, test_class_dist_no_strat):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "           f'{val:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Con estratificaci√≥n\n",
        "ax = axes[1]\n",
        "bars = ax.bar(folds, test_class_dist_strat, alpha=0.7, color='green', edgecolor='black')\n",
        "ax.axhline(30, color='red', linestyle='--', linewidth=2, label='Proporci√≥n original: 30%')\n",
        "ax.set_xlabel('Fold', fontsize=12)\n",
        "ax.set_ylabel('% Clase 1 en Test', fontsize=12)\n",
        "ax.set_title('CON Estratificaci√≥n\\n(Proporciones preservadas)', fontweight='bold', fontsize=14)\n",
        "ax.set_ylim(0, 50)\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "# A√±adir valores\n",
        "for bar, val in zip(bars, test_class_dist_strat):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "           f'{val:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Comparaci√≥n: Estratificaci√≥n en k-Fold CV', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úì Estratificaci√≥n preserva las proporciones de clase en cada fold\")\n",
        "print(f\"‚úì Esencial cuando hay desbalance de clases\")\n",
        "print(f\"‚úì Reduce varianza en la estimaci√≥n del desempe√±o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.7 Resumen de la Parte 1\n",
        "\n",
        "**Lo que hemos visto:**\n",
        "\n",
        "1. **Hold-Out Simple**\n",
        "   - ‚úì F√°cil de implementar\n",
        "   - ‚úó Alta varianza (depende de la partici√≥n)\n",
        "   - ‚úó Algunas observaciones nunca son test\n",
        "\n",
        "2. **k-Fold Cross-Validation**\n",
        "   - ‚úì Cada observaci√≥n es test exactamente 1 vez\n",
        "   - ‚úì Reduce varianza vs hold-out\n",
        "   - ‚úì Est√°ndar en la pr√°ctica (k=5 o k=10)\n",
        "\n",
        "3. **Leave-One-Out CV**\n",
        "   - ‚úì Bajo sesgo\n",
        "   - ‚úó Alto costo (n iteraciones)\n",
        "   - ‚úó Alta varianza\n",
        "   - ‚Üí Solo con datasets muy peque√±os\n",
        "\n",
        "4. **Estratificaci√≥n**\n",
        "   - ‚úì Preserva proporciones de clase\n",
        "   - ‚úì Esencial con desbalance\n",
        "   - ‚úì Reduce varianza\n",
        "\n",
        "**En las siguientes partes:**\n",
        "- Parte 2: Usaremos estas particiones para evaluar modelos de **regresi√≥n**\n",
        "- Parte 3: Usaremos estas particiones para evaluar modelos de **clasificaci√≥n**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estructura del notebook\n",
        "\n",
        "### Parte 1: Esquemas de Partici√≥n y Validaci√≥n\n",
        "* Hold-out simple\n",
        "* k-Fold Cross-Validation\n",
        "* Leave-One-Out Cross-Validation\n",
        "* Estratificaci√≥n\n",
        "\n",
        "### Parte 2: Evaluaci√≥n de Modelos de Regresi√≥n\n",
        "* M√©tricas: MAE, MSE, RMSE, R¬≤\n",
        "* Comparaci√≥n de modelos\n",
        "* An√°lisis de residuos\n",
        "\n",
        "### Parte 3: Evaluaci√≥n de Modelos de Clasificaci√≥n\n",
        "* Matriz de confusi√≥n\n",
        "* M√©tricas: Accuracy, Precision, Recall, F1\n",
        "* Curva ROC y AUC\n",
        "* Matthews Correlation Coefficient (MCC)\n",
        "\n",
        "### Parte 4: Comparaci√≥n de Modelos y Mejores Pr√°cticas\n",
        "* Variabilidad del desempe√±o\n",
        "* Data leakage (c√≥mo evitarlo)\n",
        "* Selecci√≥n de m√©tricas seg√∫n contexto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 0. Configuraci√≥n del Entorno\n",
        "\n",
        "Importaremos las bibliotecas necesarias para validaci√≥n y evaluaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manejo de datos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Visualizaci√≥n\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Configuraci√≥n de visualizaci√≥n\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "# Reproducibilidad\n",
        "np.random.seed(42)\n",
        "\n",
        "# Ignorar warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úì Bibliotecas b√°sicas importadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Machine Learning\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, \n",
        "    cross_val_score, \n",
        "    cross_validate,\n",
        "    KFold, \n",
        "    StratifiedKFold, \n",
        "    LeaveOneOut\n",
        ")\n",
        "\n",
        "# Modelos\n",
        "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.svm import SVR, SVC\n",
        "\n",
        "# Preprocesamiento\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# M√©tricas de regresi√≥n\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score\n",
        ")\n",
        "\n",
        "# M√©tricas de clasificaci√≥n\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_curve,\n",
        "    roc_auc_score,\n",
        "    matthews_corrcoef\n",
        ")\n",
        "\n",
        "# Datasets\n",
        "from sklearn.datasets import (\n",
        "    load_diabetes,\n",
        "    load_breast_cancer,\n",
        "    make_classification,\n",
        "    make_regression\n",
        ")\n",
        "\n",
        "print(\"‚úì Bibliotecas de ML importadas correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Parte 1: Esquemas de Partici√≥n y Validaci√≥n\n",
        "\n",
        "La partici√≥n de datos es fundamental para estimar la capacidad de generalizaci√≥n del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 ¬øPor qu√© particionar los datos?\n",
        "\n",
        "**Problema fundamental**:\n",
        "- El modelo se ajusta minimizando el error en los datos de entrenamiento\n",
        "- Si evaluamos en los mismos datos, el error ser√° **optimista**\n",
        "- No sabremos si el modelo **generaliza** a datos nuevos\n",
        "\n",
        "**Soluci√≥n**:\n",
        "- Separar datos en **entrenamiento** y **prueba**\n",
        "- Entrenar solo con training\n",
        "- Evaluar solo con test (datos \"no vistos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Hold-Out Simple\n",
        "\n",
        "La estrategia m√°s b√°sica: una sola partici√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset sint√©tico para regresi√≥n\n",
        "np.random.seed(42)\n",
        "X_reg, y_reg = make_regression(\n",
        "    n_samples=200, \n",
        "    n_features=10, \n",
        "    n_informative=8,\n",
        "    noise=10, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"HOLD-OUT SIMPLE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Partici√≥n 70-30\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_reg, y_reg, \n",
        "    test_size=0.3, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTotal de datos: {len(X_reg)}\")\n",
        "print(f\"  Training: {len(X_train)} ({100*len(X_train)/len(X_reg):.0f}%)\")\n",
        "print(f\"  Test: {len(X_test)} ({100*len(X_test)/len(X_reg):.0f}%)\")\n",
        "\n",
        "# Entrenar modelo simple\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predecir\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Calcular errores\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nResultados:\")\n",
        "print(f\"  MSE Training: {train_mse:.2f}\")\n",
        "print(f\"  MSE Test: {test_mse:.2f}\")\n",
        "print(f\"  R¬≤ Training: {train_r2:.3f}\")\n",
        "print(f\"  R¬≤ Test: {test_r2:.3f}\")\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  Limitaci√≥n: El resultado depende de la partici√≥n espec√≠fica\")\n",
        "print(f\"   Cambiar random_state da resultados diferentes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variabilidad del Hold-Out\n",
        "\n",
        "Veamos c√≥mo cambia el desempe√±o con diferentes particiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejecutar hold-out con diferentes semillas\n",
        "results = []\n",
        "\n",
        "for seed in range(30):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_reg, y_reg, test_size=0.3, random_state=seed\n",
        "    )\n",
        "    \n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    results.append({'seed': seed, 'MSE': mse, 'R¬≤': r2})\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Visualizaci√≥n\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# MSE\n",
        "ax = axes[0]\n",
        "ax.hist(df_results['MSE'], bins=15, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "ax.axvline(df_results['MSE'].mean(), color='red', linestyle='--', linewidth=2, label=f'Media: {df_results[\"MSE\"].mean():.2f}')\n",
        "ax.set_xlabel('MSE en Test')\n",
        "ax.set_ylabel('Frecuencia')\n",
        "ax.set_title('Variabilidad del MSE\\n(30 particiones diferentes)', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "# R¬≤\n",
        "ax = axes[1]\n",
        "ax.hist(df_results['R¬≤'], bins=15, alpha=0.7, color='green', edgecolor='black')\n",
        "ax.axvline(df_results['R¬≤'].mean(), color='red', linestyle='--', linewidth=2, label=f'Media: {df_results[\"R¬≤\"].mean():.3f}')\n",
        "ax.set_xlabel('R¬≤ en Test')\n",
        "ax.set_ylabel('Frecuencia')\n",
        "ax.set_title('Variabilidad del R¬≤\\n(30 particiones diferentes)', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"MSE: Œº = {df_results['MSE'].mean():.2f}, œÉ = {df_results['MSE'].std():.2f}\")\n",
        "print(f\"R¬≤:  Œº = {df_results['R¬≤'].mean():.3f}, œÉ = {df_results['R¬≤'].std():.3f}\")\n",
        "print(f\"\\nüí° Varianza alta ‚Üí Hold-out simple no es confiable\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 k-Fold Cross-Validation\n",
        "\n",
        "Reduce la varianza dividiendo los datos en k subconjuntos (folds)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# k-Fold CV con k=5\n",
        "print(\"=\"*80)\n",
        "print(\"K-FOLD CROSS-VALIDATION (k=5)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "# cross_validate devuelve m√∫ltiples m√©tricas\n",
        "cv_results = cross_validate(\n",
        "    model, X_reg, y_reg,\n",
        "    cv=kfold,\n",
        "    scoring=['neg_mean_squared_error', 'r2'],\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Convertir a positivo (sklearn usa negative MSE)\n",
        "train_mse = -cv_results['train_neg_mean_squared_error']\n",
        "test_mse = -cv_results['test_neg_mean_squared_error']\n",
        "train_r2 = cv_results['train_r2']\n",
        "test_r2 = cv_results['test_r2']\n",
        "\n",
        "print(f\"\\nResultados por fold:\")\n",
        "print(f\"{'Fold':<10} {'Train MSE':<15} {'Test MSE':<15} {'Train R¬≤':<15} {'Test R¬≤':<15}\")\n",
        "print(\"-\" * 70)\n",
        "for i in range(5):\n",
        "    print(f\"{i+1:<10} {train_mse[i]:<15.2f} {test_mse[i]:<15.2f} {train_r2[i]:<15.3f} {test_r2[i]:<15.3f}\")\n",
        "\n",
        "print(\"\\nEstad√≠sticas agregadas:\")\n",
        "print(f\"  Test MSE: {test_mse.mean():.2f} ¬± {test_mse.std():.2f}\")\n",
        "print(f\"  Test R¬≤:  {test_r2.mean():.3f} ¬± {test_r2.std():.3f}\")\n",
        "\n",
        "print(f\"\\n‚úì Cada observaci√≥n se usa para entrenamiento y prueba\")\n",
        "print(f\"‚úì Estimaci√≥n m√°s estable que hold-out simple\")\n",
        "\n",
        "# Visualizaci√≥n\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# MSE por fold\n",
        "ax = axes[0]\n",
        "x = np.arange(1, 6)\n",
        "ax.bar(x - 0.2, train_mse, width=0.4, label='Training', alpha=0.7, color='steelblue')\n",
        "ax.bar(x + 0.2, test_mse, width=0.4, label='Test', alpha=0.7, color='orange')\n",
        "ax.axhline(test_mse.mean(), color='red', linestyle='--', linewidth=2, label=f'Test Œº={test_mse.mean():.2f}')\n",
        "ax.set_xlabel('Fold')\n",
        "ax.set_ylabel('MSE')\n",
        "ax.set_title('MSE por Fold (5-Fold CV)', fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "# R¬≤ por fold\n",
        "ax = axes[1]\n",
        "ax.bar(x - 0.2, train_r2, width=0.4, label='Training', alpha=0.7, color='steelblue')\n",
        "ax.bar(x + 0.2, test_r2, width=0.4, label='Test', alpha=0.7, color='orange')\n",
        "ax.axhline(test_r2.mean(), color='red', linestyle='--', linewidth=2, label=f'Test Œº={test_r2.mean():.3f}')\n",
        "ax.set_xlabel('Fold')\n",
        "ax.set_ylabel('R¬≤')\n",
        "ax.set_title('R¬≤ por Fold (5-Fold CV)', fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 Leave-One-Out Cross-Validation (LOOCV)\n",
        "\n",
        "Caso extremo donde k = n (cada observaci√≥n es un fold)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LOOCV (solo con subset peque√±o por costo computacional)\n",
        "print(\"=\"*80)\n",
        "print(\"LEAVE-ONE-OUT CROSS-VALIDATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Usar solo primeras 100 observaciones para estabilidad\n",
        "X_small = X_reg[:100]\n",
        "y_small = y_reg[:100]\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Usar modelo m√°s robusto para LOOCV\n",
        "model = Ridge(alpha=1.0)\n",
        "\n",
        "# LOOCV con manejo de errores\n",
        "try:\n",
        "    scores = cross_val_score(model, X_small, y_small, cv=loo, scoring='r2')\n",
        "    \n",
        "    # Filtrar NaN si los hay\n",
        "    scores_valid = scores[~np.isnan(scores)]\n",
        "    \n",
        "    if len(scores_valid) == 0:\n",
        "        print(f\"\\n‚ö†Ô∏è  Todos los scores son NaN. Usando MAE en su lugar...\")\n",
        "        scores = cross_val_score(model, X_small, y_small, cv=loo, scoring='neg_mean_absolute_error')\n",
        "        scores = -scores  # Convertir a positivo\n",
        "        metric_name = 'MAE'\n",
        "    else:\n",
        "        scores = scores_valid\n",
        "        metric_name = 'R¬≤'\n",
        "    \n",
        "    print(f\"\\nDatos: {len(X_small)} observaciones\")\n",
        "    print(f\"Iteraciones: {loo.get_n_splits(X_small)} (una por observaci√≥n)\")\n",
        "    print(f\"\\n{metric_name} por observaci√≥n:\")\n",
        "    print(f\"  Media: {scores.mean():.3f}\")\n",
        "    print(f\"  Std: {scores.std():.3f}\")\n",
        "    print(f\"  Min: {scores.min():.3f}\")\n",
        "    print(f\"  Max: {scores.max():.3f}\")\n",
        "    \n",
        "    print(f\"\\n‚ö†Ô∏è  LOOCV:\")\n",
        "    print(f\"   ‚úì Bajo sesgo (entrena con n-1 datos)\")\n",
        "    print(f\"   ‚úó Alta varianza\")\n",
        "    print(f\"   ‚úó Alto costo computacional (n iteraciones)\")\n",
        "    print(f\"   ‚Üí Usar solo con datasets peque√±os\")\n",
        "    \n",
        "    # Visualizaci√≥n\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
        "    ax.hist(scores, bins=20, alpha=0.7, color='purple', edgecolor='black')\n",
        "    ax.axvline(scores.mean(), color='red', linestyle='--', linewidth=2, \n",
        "              label=f'Media: {scores.mean():.3f}')\n",
        "    ax.set_xlabel(f'{metric_name} Score')\n",
        "    ax.set_ylabel('Frecuencia')\n",
        "    ax.set_title(f'Distribuci√≥n de {metric_name} en LOOCV\\n({len(scores)} iteraciones)', \n",
        "                fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è  Error en LOOCV: {str(e)}\")\n",
        "    print(f\"\\nLOOCV puede ser inestable con pocos datos y regresi√≥n lineal.\")\n",
        "    print(f\"En la pr√°ctica, k-Fold CV (k=5 o k=10) es m√°s robusto.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 Estratificaci√≥n en Clasificaci√≥n\n",
        "\n",
        "Preservar proporciones de clase en cada fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset desbalanceado para clasificaci√≥n\n",
        "X_class, y_class = make_classification(\n",
        "    n_samples=200,\n",
        "    n_features=10,\n",
        "    n_informative=8,\n",
        "    n_classes=2,\n",
        "    weights=[0.7, 0.3],  # 70% clase 0, 30% clase 1\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ESTRATIFICACI√ìN EN CLASIFICACI√ìN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nDistribuci√≥n original:\")\n",
        "unique, counts = np.unique(y_class, return_counts=True)\n",
        "for cls, count in zip(unique, counts):\n",
        "    print(f\"  Clase {cls}: {count} ({100*count/len(y_class):.1f}%)\")\n",
        "\n",
        "# CV SIN estratificaci√≥n\n",
        "print(f\"\\n--- K-Fold CV SIN estratificaci√≥n ---\")\n",
        "kfold_no_strat = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for i, (train_idx, test_idx) in enumerate(kfold_no_strat.split(X_class), 1):\n",
        "    y_test_fold = y_class[test_idx]\n",
        "    class_1_pct = 100 * (y_test_fold == 1).sum() / len(y_test_fold)\n",
        "    print(f\"  Fold {i}: {class_1_pct:.1f}% clase 1 en test\")\n",
        "\n",
        "# CV CON estratificaci√≥n\n",
        "print(f\"\\n--- K-Fold CV CON estratificaci√≥n ---\")\n",
        "kfold_strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for i, (train_idx, test_idx) in enumerate(kfold_strat.split(X_class, y_class), 1):\n",
        "    y_test_fold = y_class[test_idx]\n",
        "    class_1_pct = 100 * (y_test_fold == 1).sum() / len(y_test_fold)\n",
        "    print(f\"  Fold {i}: {class_1_pct:.1f}% clase 1 en test\")\n",
        "\n",
        "print(f\"\\n‚úì Estratificaci√≥n preserva las proporciones originales\")\n",
        "print(f\"‚úì Esencial con clases desbalanceadas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Parte 2: Evaluaci√≥n de Modelos de Regresi√≥n\n",
        "\n",
        "M√©tricas para problemas donde la variable objetivo es continua."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Dataset: Diabetes\n",
        "\n",
        "Usaremos el dataset cl√°sico de diabetes para predecir progresi√≥n de la enfermedad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset\n",
        "diabetes = load_diabetes()\n",
        "X_diabetes = diabetes.data\n",
        "y_diabetes = diabetes.target\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DATASET: Diabetes\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nObservaciones: {X_diabetes.shape[0]}\")\n",
        "print(f\"Features: {X_diabetes.shape[1]}\")\n",
        "print(f\"\\nVariable objetivo: Progresi√≥n de diabetes (continua)\")\n",
        "print(f\"  Min: {y_diabetes.min():.1f}\")\n",
        "print(f\"  Max: {y_diabetes.max():.1f}\")\n",
        "print(f\"  Media: {y_diabetes.mean():.1f}\")\n",
        "print(f\"  Std: {y_diabetes.std():.1f}\")\n",
        "\n",
        "# Partici√≥n\n",
        "X_train_diab, X_test_diab, y_train_diab, y_test_diab = train_test_split(\n",
        "    X_diabetes, y_diabetes, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nPartici√≥n 70-30:\")\n",
        "print(f\"  Training: {len(X_train_diab)}\")\n",
        "print(f\"  Test: {len(X_test_diab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 M√©tricas de Regresi√≥n\n",
        "\n",
        "Compararemos MAE, MSE, RMSE y R¬≤ en diferentes modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_regression_model(model, X_train, X_test, y_train, y_test, model_name):\n",
        "    \"\"\"\n",
        "    Eval√∫a un modelo de regresi√≥n con m√∫ltiples m√©tricas\n",
        "    \"\"\"\n",
        "    # Entrenar\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Predecir\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    \n",
        "    # Calcular m√©tricas\n",
        "    metrics = {\n",
        "        'Model': model_name,\n",
        "        'Train MAE': mean_absolute_error(y_train, y_train_pred),\n",
        "        'Test MAE': mean_absolute_error(y_test, y_test_pred),\n",
        "        'Train MSE': mean_squared_error(y_train, y_train_pred),\n",
        "        'Test MSE': mean_squared_error(y_test, y_test_pred),\n",
        "        'Train RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "        'Test RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
        "        'Train R¬≤': r2_score(y_train, y_train_pred),\n",
        "        'Test R¬≤': r2_score(y_test, y_test_pred)\n",
        "    }\n",
        "    \n",
        "    return metrics, y_test_pred\n",
        "\n",
        "# Modelos a comparar\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge (Œ±=1.0)': Ridge(alpha=1.0),\n",
        "    'Decision Tree': DecisionTreeRegressor(max_depth=5, random_state=42),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42),\n",
        "    'KNN (k=5)': KNeighborsRegressor(n_neighbors=5)\n",
        "}\n",
        "\n",
        "results = []\n",
        "predictions = {}\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPARACI√ìN DE MODELOS - REGRESI√ìN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name, model in models.items():\n",
        "    metrics, y_pred = evaluate_regression_model(\n",
        "        model, X_train_diab, X_test_diab, y_train_diab, y_test_diab, name\n",
        "    )\n",
        "    results.append(metrics)\n",
        "    predictions[name] = y_pred\n",
        "    print(f\"‚úì {name}\")\n",
        "\n",
        "df_results_reg = pd.DataFrame(results)\n",
        "print(f\"\\n{df_results_reg.to_string(index=False)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizaci√≥n de Resultados\n",
        "\n",
        "Comparemos las m√©tricas y las predicciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizaci√≥n de m√©tricas\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "metrics_to_plot = [\n",
        "    ('Test MAE', 'MAE en Test', 'steelblue'),\n",
        "    ('Test RMSE', 'RMSE en Test', 'orange'),\n",
        "    ('Test R¬≤', 'R¬≤ en Test', 'green'),\n",
        "]\n",
        "\n",
        "for idx, (metric, title, color) in enumerate(metrics_to_plot):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "    \n",
        "    values = df_results_reg[metric].values\n",
        "    models_names = df_results_reg['Model'].values\n",
        "    \n",
        "    bars = ax.barh(models_names, values, color=color, alpha=0.7, edgecolor='black')\n",
        "    ax.set_xlabel(metric, fontsize=11)\n",
        "    ax.set_title(title, fontweight='bold', fontsize=13)\n",
        "    ax.grid(alpha=0.3, axis='x')\n",
        "    \n",
        "    # A√±adir valores\n",
        "    for bar, val in zip(bars, values):\n",
        "        width = bar.get_width()\n",
        "        ax.text(width, bar.get_y() + bar.get_height()/2,\n",
        "               f' {val:.2f}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Predicciones vs Real (mejor modelo por R¬≤)\n",
        "ax = axes[1, 1]\n",
        "best_model_name = df_results_reg.loc[df_results_reg['Test R¬≤'].idxmax(), 'Model']\n",
        "y_pred_best = predictions[best_model_name]\n",
        "\n",
        "ax.scatter(y_test_diab, y_pred_best, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
        "ax.plot([y_test_diab.min(), y_test_diab.max()], \n",
        "        [y_test_diab.min(), y_test_diab.max()], \n",
        "        'r--', linewidth=2, label='Predicci√≥n perfecta')\n",
        "ax.set_xlabel('Valores Reales', fontsize=11)\n",
        "ax.set_ylabel('Valores Predichos', fontsize=11)\n",
        "ax.set_title(f'Predicciones vs Reales\\n(Mejor modelo: {best_model_name})', fontweight='bold', fontsize=13)\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('Comparaci√≥n de Modelos de Regresi√≥n', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüèÜ Mejor modelo por R¬≤: {best_model_name}\")\n",
        "print(f\"   Test R¬≤: {df_results_reg.loc[df_results_reg['Test R¬≤'].idxmax(), 'Test R¬≤']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 An√°lisis de Residuos\n",
        "\n",
        "Los residuos revelan patrones de error del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lisis de residuos del mejor modelo\n",
        "best_model_idx = df_results_reg['Test R¬≤'].idxmax()\n",
        "best_model_name = df_results_reg.loc[best_model_idx, 'Model']\n",
        "y_pred_best = predictions[best_model_name]\n",
        "\n",
        "residuals = y_test_diab - y_pred_best\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Distribuci√≥n de residuos\n",
        "ax = axes[0]\n",
        "ax.hist(residuals, bins=20, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Cero')\n",
        "ax.axvline(residuals.mean(), color='orange', linestyle='--', linewidth=2, label=f'Media: {residuals.mean():.2f}')\n",
        "ax.set_xlabel('Residuos')\n",
        "ax.set_ylabel('Frecuencia')\n",
        "ax.set_title('Distribuci√≥n de Residuos', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "# Residuos vs Predicciones\n",
        "ax = axes[1]\n",
        "ax.scatter(y_pred_best, residuals, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
        "ax.axhline(0, color='red', linestyle='--', linewidth=2)\n",
        "ax.set_xlabel('Valores Predichos')\n",
        "ax.set_ylabel('Residuos')\n",
        "ax.set_title('Residuos vs Predicciones', fontweight='bold')\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "# Q-Q plot\n",
        "ax = axes[2]\n",
        "stats.probplot(residuals, dist=\"norm\", plot=ax)\n",
        "ax.set_title('Q-Q Plot (normalidad de residuos)', fontweight='bold')\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'An√°lisis de Residuos: {best_model_name}', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Estad√≠sticas de residuos:\")\n",
        "print(f\"  Media: {residuals.mean():.2f} (debe estar cerca de 0)\")\n",
        "print(f\"  Std: {residuals.std():.2f}\")\n",
        "print(f\"  Min: {residuals.min():.2f}\")\n",
        "print(f\"  Max: {residuals.max():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Parte 3: Evaluaci√≥n de Modelos de Clasificaci√≥n\n",
        "\n",
        "M√©tricas para problemas donde la variable objetivo es categ√≥rica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Dataset: Breast Cancer\n",
        "\n",
        "Usaremos el dataset Wisconsin Breast Cancer (clasificaci√≥n binaria)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset\n",
        "cancer = load_breast_cancer()\n",
        "X_cancer = cancer.data\n",
        "y_cancer = cancer.target\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DATASET: Wisconsin Breast Cancer\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nObservaciones: {X_cancer.shape[0]}\")\n",
        "print(f\"Features: {X_cancer.shape[1]}\")\n",
        "print(f\"\\nClases:\")\n",
        "unique, counts = np.unique(y_cancer, return_counts=True)\n",
        "for cls, count, name in zip(unique, counts, cancer.target_names):\n",
        "    print(f\"  {cls} ({name}): {count} ({100*count/len(y_cancer):.1f}%)\")\n",
        "\n",
        "# Partici√≥n estratificada\n",
        "X_train_canc, X_test_canc, y_train_canc, y_test_canc = train_test_split(\n",
        "    X_cancer, y_cancer, test_size=0.3, random_state=42, stratify=y_cancer\n",
        ")\n",
        "\n",
        "print(f\"\\nPartici√≥n estratificada 70-30:\")\n",
        "print(f\"  Training: {len(X_train_canc)}\")\n",
        "print(f\"  Test: {len(X_test_canc)}\")\n",
        "\n",
        "# Verificar estratificaci√≥n\n",
        "print(f\"\\nDistribuci√≥n en test:\")\n",
        "unique, counts = np.unique(y_test_canc, return_counts=True)\n",
        "for cls, count in zip(unique, counts):\n",
        "    print(f\"  Clase {cls}: {count} ({100*count/len(y_test_canc):.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Matriz de Confusi√≥n\n",
        "\n",
        "La base para todas las m√©tricas de clasificaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, class_names, model_name):\n",
        "    \"\"\"\n",
        "    Visualiza la matriz de confusi√≥n\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
        "    \n",
        "    # Heatmap\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                cbar_kws={'label': 'Cuenta'}, ax=ax)\n",
        "    \n",
        "    ax.set_ylabel('Clase Real', fontsize=12)\n",
        "    ax.set_xlabel('Clase Predicha', fontsize=12)\n",
        "    ax.set_title(f'Matriz de Confusi√≥n\\n{model_name}', fontweight='bold', fontsize=14)\n",
        "    \n",
        "    # A√±adir anotaciones TN, FP, FN, TP\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    annotations = [\n",
        "        (0, 0, f'TN={tn}'),\n",
        "        (1, 0, f'FP={fp}'),\n",
        "        (0, 1, f'FN={fn}'),\n",
        "        (1, 1, f'TP={tp}')\n",
        "    ]\n",
        "    \n",
        "    for x, y, text in annotations:\n",
        "        ax.text(x + 0.5, y + 0.75, text, ha='center', va='center',\n",
        "               fontsize=10, color='darkred', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig, cm\n",
        "\n",
        "# Entrenar modelo simple\n",
        "model_lr = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model_lr.fit(X_train_canc, y_train_canc)\n",
        "y_pred_lr = model_lr.predict(X_test_canc)\n",
        "\n",
        "# Matriz de confusi√≥n\n",
        "fig_cm, cm = plot_confusion_matrix(y_test_canc, y_pred_lr, cancer.target_names, 'Logistic Regression')\n",
        "plt.show()\n",
        "\n",
        "# M√©tricas b√°sicas\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(\"=\"*80)\n",
        "print(\"M√âTRICAS DESDE LA MATRIZ DE CONFUSI√ìN\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nVerdaderos Negativos (TN): {tn}\")\n",
        "print(f\"Falsos Positivos (FP):     {fp}  ‚Üê Error Tipo I\")\n",
        "print(f\"Falsos Negativos (FN):     {fn}  ‚Üê Error Tipo II\")\n",
        "print(f\"Verdaderos Positivos (TP): {tp}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 M√©tricas de Clasificaci√≥n\n",
        "\n",
        "Calculemos todas las m√©tricas principales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_classification_metrics(y_true, y_pred, y_pred_proba=None):\n",
        "    \"\"\"\n",
        "    Calcula todas las m√©tricas de clasificaci√≥n\n",
        "    \"\"\"\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'F1-Score': f1_score(y_true, y_pred),\n",
        "        'MCC': matthews_corrcoef(y_true, y_pred)\n",
        "    }\n",
        "    \n",
        "    if y_pred_proba is not None:\n",
        "        metrics['ROC-AUC'] = roc_auc_score(y_true, y_pred_proba)\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "# M√©tricas para Logistic Regression\n",
        "y_pred_proba_lr = model_lr.predict_proba(X_test_canc)[:, 1]\n",
        "metrics_lr = calculate_classification_metrics(y_test_canc, y_pred_lr, y_pred_proba_lr)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"M√âTRICAS DE CLASIFICACI√ìN - Logistic Regression\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for metric, value in metrics_lr.items():\n",
        "    print(f\"{metric:15s}: {value:.4f}\")\n",
        "\n",
        "print(f\"\\nInterpretaci√≥n:\")\n",
        "print(f\"  ‚Ä¢ Accuracy:  {metrics_lr['Accuracy']:.1%} de predicciones correctas\")\n",
        "print(f\"  ‚Ä¢ Precision: {metrics_lr['Precision']:.1%} de positivos predichos son correctos\")\n",
        "print(f\"  ‚Ä¢ Recall:    {metrics_lr['Recall']:.1%} de positivos reales fueron detectados\")\n",
        "print(f\"  ‚Ä¢ F1-Score:  Media arm√≥nica de Precision y Recall\")\n",
        "print(f\"  ‚Ä¢ MCC:       Correlaci√≥n entre predicci√≥n y realidad [-1, 1]\")\n",
        "print(f\"  ‚Ä¢ ROC-AUC:   √Årea bajo la curva ROC [0.5, 1.0]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.4 Curva ROC y AUC\n",
        "\n",
        "La curva ROC eval√∫a el desempe√±o variando el umbral de clasificaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test_canc, y_pred_proba_lr)\n",
        "roc_auc = roc_auc_score(y_test_canc, y_pred_proba_lr)\n",
        "\n",
        "# Visualizaci√≥n\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Curva ROC\n",
        "ax = axes[0]\n",
        "ax.plot(fpr, tpr, linewidth=3, label=f'Logistic Regression (AUC = {roc_auc:.3f})', color='steelblue')\n",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Clasificador aleatorio (AUC = 0.5)', alpha=0.5)\n",
        "ax.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
        "ax.set_ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
        "ax.set_title('Curva ROC', fontweight='bold', fontsize=14)\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(alpha=0.3)\n",
        "ax.set_xlim([-0.05, 1.05])\n",
        "ax.set_ylim([-0.05, 1.05])\n",
        "\n",
        "# Umbral √≥ptimo\n",
        "# Criterio: maximizar TPR - FPR\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "ax.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=10, \n",
        "        label=f'Umbral √≥ptimo: {optimal_threshold:.3f}')\n",
        "ax.legend(fontsize=11)\n",
        "\n",
        "# Distribuci√≥n de probabilidades\n",
        "ax = axes[1]\n",
        "y_pred_proba_class0 = y_pred_proba_lr[y_test_canc == 0]\n",
        "y_pred_proba_class1 = y_pred_proba_lr[y_test_canc == 1]\n",
        "\n",
        "ax.hist(y_pred_proba_class0, bins=30, alpha=0.6, color='red', label='Clase 0 (Maligno)', edgecolor='black')\n",
        "ax.hist(y_pred_proba_class1, bins=30, alpha=0.6, color='green', label='Clase 1 (Benigno)', edgecolor='black')\n",
        "ax.axvline(0.5, color='black', linestyle='--', linewidth=2, label='Umbral por defecto: 0.5')\n",
        "ax.axvline(optimal_threshold, color='orange', linestyle='--', linewidth=2, label=f'Umbral √≥ptimo: {optimal_threshold:.3f}')\n",
        "ax.set_xlabel('Probabilidad predicha (clase 1)', fontsize=12)\n",
        "ax.set_ylabel('Frecuencia', fontsize=12)\n",
        "ax.set_title('Distribuci√≥n de Probabilidades Predichas', fontweight='bold', fontsize=14)\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('An√°lisis ROC y Probabilidades', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "print(f\"Interpretaci√≥n: Probabilidad de que el modelo asigne mayor score a un\")\n",
        "print(f\"                positivo real que a un negativo real\")\n",
        "print(f\"\\nUmbral √≥ptimo: {optimal_threshold:.3f} (vs 0.5 por defecto)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5 Comparaci√≥n de M√∫ltiples Modelos\n",
        "\n",
        "Evaluemos diferentes clasificadores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_classifier(model, X_train, X_test, y_train, y_test, model_name):\n",
        "    \"\"\"\n",
        "    Eval√∫a un modelo de clasificaci√≥n con todas las m√©tricas\n",
        "    \"\"\"\n",
        "    # Entrenar\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Predecir\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "    \n",
        "    # M√©tricas\n",
        "    metrics = {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1-Score': f1_score(y_test, y_pred),\n",
        "        'MCC': matthews_corrcoef(y_test, y_pred)\n",
        "    }\n",
        "    \n",
        "    if y_pred_proba is not None:\n",
        "        metrics['ROC-AUC'] = roc_auc_score(y_test, y_pred_proba)\n",
        "    else:\n",
        "        metrics['ROC-AUC'] = np.nan\n",
        "    \n",
        "    return metrics, y_pred, y_pred_proba\n",
        "\n",
        "# Modelos a comparar\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=10000, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
        "    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5),\n",
        "    'SVM (linear)': SVC(kernel='linear', probability=True, random_state=42)\n",
        "}\n",
        "\n",
        "results_class = []\n",
        "predictions_class = {}\n",
        "probas_class = {}\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPARACI√ìN DE CLASIFICADORES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name, model in classifiers.items():\n",
        "    metrics, y_pred, y_proba = evaluate_classifier(\n",
        "        model, X_train_canc, X_test_canc, y_train_canc, y_test_canc, name\n",
        "    )\n",
        "    results_class.append(metrics)\n",
        "    predictions_class[name] = y_pred\n",
        "    probas_class[name] = y_proba\n",
        "    print(f\"‚úì {name}\")\n",
        "\n",
        "df_results_class = pd.DataFrame(results_class)\n",
        "print(f\"\\n{df_results_class.to_string(index=False)}\")\n",
        "\n",
        "# Identificar mejor modelo\n",
        "best_f1_idx = df_results_class['F1-Score'].idxmax()\n",
        "best_model_name = df_results_class.loc[best_f1_idx, 'Model']\n",
        "print(f\"\\nüèÜ Mejor modelo por F1-Score: {best_model_name}\")\n",
        "print(f\"   F1-Score: {df_results_class.loc[best_f1_idx, 'F1-Score']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizaci√≥n Comparativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizaci√≥n de m√©tricas\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'MCC', 'ROC-AUC']\n",
        "colors = ['steelblue', 'orange', 'green', 'red', 'purple', 'brown']\n",
        "\n",
        "for idx, (metric, color) in enumerate(zip(metrics_names, colors)):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    values = df_results_class[metric].values\n",
        "    models = df_results_class['Model'].values\n",
        "    \n",
        "    bars = ax.barh(models, values, color=color, alpha=0.7, edgecolor='black')\n",
        "    ax.set_xlabel(metric, fontsize=11)\n",
        "    ax.set_title(metric, fontweight='bold', fontsize=13)\n",
        "    ax.grid(alpha=0.3, axis='x')\n",
        "    ax.set_xlim(0, 1.05)\n",
        "    \n",
        "    # A√±adir valores\n",
        "    for bar, val in zip(bars, values):\n",
        "        if not np.isnan(val):\n",
        "            width = bar.get_width()\n",
        "            ax.text(width + 0.02, bar.get_y() + bar.get_height()/2,\n",
        "                   f'{val:.3f}', ha='left', va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Comparaci√≥n de Clasificadores - Todas las M√©tricas', \n",
        "            fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Parte 4: Mejores Pr√°cticas en Validaci√≥n\n",
        "\n",
        "C√≥mo evitar errores comunes y obtener evaluaciones confiables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Data Leakage: El Enemigo Silencioso\n",
        "\n",
        "La fuga de informaci√≥n invalida la evaluaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"EJEMPLO DE DATA LEAKAGE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Crear dataset simple\n",
        "X_leak, y_leak = make_classification(n_samples=200, n_features=10, random_state=42)\n",
        "\n",
        "print(f\"\\n--- INCORRECTO: Escalar antes de dividir ---\")\n",
        "# ‚ùå MAL: Escalar con todo el dataset\n",
        "scaler_wrong = StandardScaler()\n",
        "X_scaled_wrong = scaler_wrong.fit_transform(X_leak)\n",
        "\n",
        "# Luego dividir\n",
        "X_train_wrong, X_test_wrong, y_train_wrong, y_test_wrong = train_test_split(\n",
        "    X_scaled_wrong, y_leak, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Entrenar y evaluar\n",
        "model_wrong = LogisticRegression(max_iter=1000)\n",
        "model_wrong.fit(X_train_wrong, y_train_wrong)\n",
        "acc_wrong = model_wrong.score(X_test_wrong, y_test_wrong)\n",
        "\n",
        "print(f\"Accuracy (con leakage): {acc_wrong:.4f}\")\n",
        "print(f\"‚ö†Ô∏è  El scaler vio TODO el dataset ‚Üí informaci√≥n del test filtr√≥ al train\")\n",
        "\n",
        "print(f\"\\n--- CORRECTO: Escalar solo con training ---\")\n",
        "# ‚úÖ BIEN: Primero dividir\n",
        "X_train_right, X_test_right, y_train_right, y_test_right = train_test_split(\n",
        "    X_leak, y_leak, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Luego escalar solo con training\n",
        "scaler_right = StandardScaler()\n",
        "X_train_scaled = scaler_right.fit_transform(X_train_right)\n",
        "X_test_scaled = scaler_right.transform(X_test_right)  # Solo transform, NO fit_transform\n",
        "\n",
        "# Entrenar y evaluar\n",
        "model_right = LogisticRegression(max_iter=1000)\n",
        "model_right.fit(X_train_scaled, y_train_right)\n",
        "acc_right = model_right.score(X_test_scaled, y_test_right)\n",
        "\n",
        "print(f\"Accuracy (sin leakage): {acc_right:.4f}\")\n",
        "print(f\"‚úì El scaler solo vio training ‚Üí evaluaci√≥n v√°lida\")\n",
        "\n",
        "print(f\"\\nDiferencia: {acc_wrong - acc_right:.4f}\")\n",
        "print(f\"La evaluaci√≥n con leakage es artificialmente optimista!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 Usando Pipelines para Evitar Leakage\n",
        "\n",
        "Los pipelines automatizan el flujo correcto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Pipeline correcto\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Cross-validation con pipeline\n",
        "cv_scores = cross_val_score(pipeline, X_leak, y_leak, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PIPELINE + CROSS-VALIDATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nAccuracy por fold:\")\n",
        "for i, score in enumerate(cv_scores, 1):\n",
        "    print(f\"  Fold {i}: {score:.4f}\")\n",
        "\n",
        "print(f\"\\nMedia: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
        "print(f\"\\n‚úì El pipeline garantiza que el escalamiento se hace DENTRO de cada fold\")\n",
        "print(f\"‚úì No hay leakage entre training y test en ning√∫n fold\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Selecci√≥n de M√©tricas Seg√∫n Contexto\n",
        "\n",
        "No existe una m√©trica universalmente superior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"GU√çA DE SELECCI√ìN DE M√âTRICAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\"\"\n",
        "üìä REGRESI√ìN:\n",
        "  M√©trica    | Cu√°ndo usar                        | Sensibilidad a outliers\n",
        "  -----------|------------------------------------|-----------------------\n",
        "  MAE        | Errores en escala original         | Baja (lineal)\n",
        "  MSE        | Penalizar errores grandes          | Alta (cuadr√°tica)\n",
        "  RMSE       | MSE en escala original             | Alta (cuadr√°tica)\n",
        "  R¬≤         | Proporci√≥n de varianza explicada   | Media\n",
        "\n",
        "üéØ CLASIFICACI√ìN (Binaria):\n",
        "  Escenario                      | M√©trica prioritaria\n",
        "  -------------------------------|--------------------\n",
        "  Clases balanceadas             | Accuracy, F1-Score\n",
        "  Clases desbalanceadas          | F1, MCC, ROC-AUC\n",
        "  Minimizar falsos positivos     | Precision\n",
        "  Minimizar falsos negativos     | Recall (Sensitivity)\n",
        "  Balance precision-recall       | F1-Score\n",
        "  Todas las celdas de CM         | MCC\n",
        "  Evaluar umbral variable        | ROC-AUC\n",
        "\n",
        "‚öïÔ∏è EJEMPLOS PR√ÅCTICOS:\n",
        "  Problema                | Por qu√©                           | M√©trica\n",
        "  ------------------------|-----------------------------------|----------\n",
        "  Diagn√≥stico c√°ncer      | FN son cr√≠ticos (no detectar)     | Recall\n",
        "  Detecci√≥n fraude        | FP son costosos (falsa alarma)    | Precision\n",
        "  Spam filtering          | Balance FP y FN                   | F1-Score\n",
        "  Clases muy desbalanceadas| Accuracy enga√±osa                | MCC, F1\n",
        "  \n",
        "‚ö†Ô∏è  IMPORTANTE:\n",
        "  ‚Ä¢ Accuracy es enga√±osa con desbalance (puede ser alta prediciendo siempre la mayor√≠a)\n",
        "  ‚Ä¢ Precision y Recall son opuestos (mejora de uno empeora el otro)\n",
        "  ‚Ä¢ F1 balancea Precision y Recall\n",
        "  ‚Ä¢ MCC es robusto con cualquier distribuci√≥n de clases\n",
        "  ‚Ä¢ ROC-AUC eval√∫a todos los posibles umbrales\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Resumen y Conclusiones\n",
        "\n",
        "## ‚úÖ Lo que hemos aprendido\n",
        "\n",
        "### 1. Partici√≥n de Datos\n",
        "* **Hold-out simple**: R√°pido pero con alta varianza\n",
        "* **k-Fold CV**: Est√°ndar pr√°ctico (k=5 t√≠picamente)\n",
        "* **Leave-One-Out**: Bajo sesgo, alta varianza, costoso\n",
        "* **Estratificaci√≥n**: Esencial con clases desbalanceadas\n",
        "\n",
        "### 2. M√©tricas de Regresi√≥n\n",
        "* **MAE**: Robusto a outliers, escala original\n",
        "* **MSE**: Penaliza errores grandes, sensible a outliers\n",
        "* **RMSE**: MSE en escala original\n",
        "* **R¬≤**: Proporci√≥n de varianza explicada\n",
        "\n",
        "### 3. M√©tricas de Clasificaci√≥n\n",
        "* **Accuracy**: Simple pero enga√±osa con desbalance\n",
        "* **Precision**: De los positivos predichos, cu√°ntos son correctos\n",
        "* **Recall**: De los positivos reales, cu√°ntos detectamos\n",
        "* **F1-Score**: Balance entre Precision y Recall\n",
        "* **ROC-AUC**: Desempe√±o agregado en todos los umbrales\n",
        "* **MCC**: Robusto con cualquier distribuci√≥n de clases\n",
        "\n",
        "### 4. Mejores Pr√°cticas\n",
        "* **Evitar data leakage**: Preprocesar DENTRO de cada fold\n",
        "* **Usar pipelines**: Automatizan el flujo correcto\n",
        "* **Reportar varianza**: El desempe√±o no es un n√∫mero fijo\n",
        "* **Seleccionar m√©trica apropiada**: Seg√∫n el contexto del problema\n",
        "\n",
        "## üéØ Principios Clave\n",
        "\n",
        "1. **Sin partici√≥n no hay evaluaci√≥n v√°lida**\n",
        "2. **El error en training es optimista**\n",
        "3. **Cross-validation reduce varianza**\n",
        "4. **La m√©trica debe reflejar el objetivo del problema**\n",
        "5. **Data leakage invalida la evaluaci√≥n**\n",
        "\n",
        "## üìö Pr√≥ximos Pasos\n",
        "\n",
        "En m√≥dulos posteriores veremos:\n",
        "* Optimizaci√≥n de hiperpar√°metros\n",
        "* Nested cross-validation\n",
        "* Evaluaci√≥n de modelos complejos\n",
        "* Interpretabilidad de resultados\n",
        "\n",
        "---\n",
        "\n",
        "**¬°Excelente trabajo!** üéâ  \n",
        "Has completado el m√≥dulo de validaci√≥n y evaluaci√≥n de modelos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
